{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Demo of the data API"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This demo shows the abstract data API from the user point of view, using a toy example where the data is entirely loaded in memory in a hierarchical pure Python structure. The next step will be to implement this API on top of HDF5 files rather that in-memory data.\n",
      "\n",
      "The point is that the exact same user code will work with whatever underlying data structure. This adds an abstraction level between the programs and the low-level data structure."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from spikedetekt2.utils.wrap import wrap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nchannels = 32\n",
      "nspikes = 100\n",
      "nclusters = 10\n",
      "maxcolors = 30\n",
      "fetdim = 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We just define a few fields here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp = wrap({ 'shanks': [{\n",
      "               'channels': \n",
      "                   {\n",
      "                        'name': [str(i) for i in range(nchannels)],\n",
      "                        'klustaviewa':\n",
      "                            {\n",
      "                                 'color': [i % maxcolors for i in range(nchannels)],\n",
      "                             }\n",
      "                    },\n",
      "                'spikes': \n",
      "                    {\n",
      "                         'features': np.random.rand(nspikes, fetdim * nchannels),\n",
      "                         'cluster': np.random.randint(size=nspikes, low=0, high=nclusters),\n",
      "                     }\n",
      "               }]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is how we access the KlustaViewa-related information about channel #4 in shank #0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(exp.shanks[0].channels[4].klustaviewa.color)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we retrieve all spikes from shank #0. The `spikes` object can be accessed with attributes or indices."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# All spikes in the first shank.\n",
      "spikes = exp.shanks[0].spikes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This variable is a NumPy array with the clusters for all spikes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For all spikes, the cluster.\n",
      "spike_clusters = spikes.cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The \"indexing\" and \"attribute access\" operations commute!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cluster of spike #10: two ways of accessing the same bit of data.\n",
      "spikes[10].cluster == spikes.cluster[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Accessing all spikes from cluster 3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get all spikes in cluster 3.\n",
      "indices = spike_clusters == 3\n",
      "spikes_in_3 = spikes[indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Accessing all spikes from a selection of the clusters. This method is very efficient as it uses a NumPy compiled function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get all spikes belong in one of the selected clusters.\n",
      "clusters_sel = [2, 3, 5, 7]\n",
      "indices = np.in1d(spike_clusters, clusters_sel)\n",
      "myspikes = spikes[indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We end up with an object \"myspikes\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(spikes.features.shape)\n",
      "print(myspikes.features.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100L, 96L)\n",
        "(40L, 96L)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can add items."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spikes.append({'features': np.random.rand(1, fetdim * nchannels),\n",
      "               'cluster': 2})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(spikes.features.shape)\n",
      "print(spikes.cluster.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(101L, 96L)\n",
        "(101L,)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This proof-of-concept shows that this interface can work with Python dictionaries. The next step is to implement the same interface on HDF5 files instead. The exact structure used for these files does not matter as long as the interface is respected. We could write a battery of tests to make sure that a new interface is compliant..."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}